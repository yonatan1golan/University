{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import KBinsDiscretizer, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import KNNImputer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Models\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from itertools import product\n",
    "\n",
    "# Plotting\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'XY_train.csv'\n",
    "current_dir = os.getcwd()\n",
    "file_path = os.path.join(current_dir, 'XY_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_values(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Input: a dataframe that contains missing values\n",
    "    Returns: a dataframe that doesn't contain any missing values using knn imputation\n",
    "    \"\"\"\n",
    "\n",
    "    columns_with_missing_values = df.columns[df.isnull().any()].tolist()\n",
    "    imputer = KNNImputer(n_neighbors = 5)\n",
    "    df[columns_with_missing_values] = imputer.fit_transform(df[columns_with_missing_values])\n",
    "    return df\n",
    "\n",
    "def fix_irrational_driving_age(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Input: a dataframe that contains the driving age column with irrational values\n",
    "    Returns: a dataframe with the driving age column fixed with minimum value of 16\n",
    "    \"\"\"\n",
    "    df['LICENSE_AGE'] = df['AGE'] - df['DRIVING_EXPERIENCE']\n",
    "    df['DRIVING_EXPERIENCE'] = np.where(df['LICENSE_AGE'] < 16, df['AGE'] - 16, df['DRIVING_EXPERIENCE'])\n",
    "    df['LICENSE_AGE'] = df['AGE'] - df['DRIVING_EXPERIENCE'] # update the license age\n",
    "    return df.drop(columns = ['LICENSE_AGE'])\n",
    "\n",
    "def get_categorial_mapping(df: pd.DataFrame, categorical_columns: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Input: categorial columns and the dataframe itself\n",
    "    Returns: a dictionary that contains the mapping of the categorial values to integers\n",
    "    \"\"\"\n",
    "    indexed_mappings = {}\n",
    "    for col in categorical_columns.columns:\n",
    "        unique_values = df[col].unique()\n",
    "        mapping = {value: idx for idx, value in enumerate(unique_values)}\n",
    "        indexed_mappings[col] = mapping\n",
    "    return indexed_mappings\n",
    "\n",
    "def kbin_normal_distribution(column: pd.Series, n_bins: int = 3):\n",
    "    \"\"\"\n",
    "    Input: a column that contains continous numerical values\n",
    "    Returns: a column that contains the binned values of the input column\n",
    "    \"\"\"\n",
    "    if column.nunique() == 1:\n",
    "        return pd.Series([0] * len(column), index=column.index)\n",
    "\n",
    "    column_reshaped = column.values.reshape(-1, 1)\n",
    "    n_bins = min(n_bins, column.nunique())\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", message=\".*Feature 0 is constant.*\")\n",
    "        warnings.filterwarnings(\"ignore\", message=\".*Bins whose width are too small.*\")\n",
    "        kbin = KBinsDiscretizer(n_bins=n_bins, encode='ordinal', strategy='quantile')\n",
    "        binned_column = kbin.fit_transform(column_reshaped).astype(int)\n",
    "    return pd.Series(binned_column.flatten(), index=column.index)\n",
    "\n",
    "def kbin_exp_distribution(column: pd.Series, n_bins: int = 3):\n",
    "    \"\"\"\n",
    "    Input: a column that contains continous numerical values but with exponential distribution\n",
    "    Returns: a column that contains the binned values of the input column\n",
    "    \"\"\"\n",
    "    if column.nunique() == 1:\n",
    "        return pd.Series([0] * len(column), index=column.index)\n",
    "\n",
    "    if column.min() <= 0:\n",
    "        column = column + abs(column.min()) + 1\n",
    "\n",
    "    log_column = np.log(column)\n",
    "    column_reshaped = log_column.values.reshape(-1, 1)\n",
    "    n_bins = min(n_bins, column.nunique())\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", message=\".*Feature 0 is constant.*\")\n",
    "        warnings.filterwarnings(\"ignore\", message=\".*Bins whose width are too small.*\")\n",
    "        kbin = KBinsDiscretizer(n_bins=n_bins, encode='ordinal', strategy='quantile')\n",
    "        binned_column = kbin.fit_transform(column_reshaped).astype(int)\n",
    "    return pd.Series(binned_column.flatten(), index=column.index)\n",
    "\n",
    "def categorize_age_attribute(age: int):\n",
    "    \"\"\"\n",
    "    Input: age in the form of integer\n",
    "    Returns: a string that represents the age category\n",
    "    Logic:\n",
    "    Age will be categorized as weight, so the very young and very old people will be considered as high risk\n",
    "    \"\"\"\n",
    "    if age <= 24: return 3 \n",
    "    elif age <= 65: return 1\n",
    "    return 2\n",
    "\n",
    "def categorize_driving_experience(years: int):\n",
    "    \"\"\"\n",
    "    Input: years of driving experience in the form of integer\n",
    "    Returns: a string that represents the driving experience category\n",
    "    Logic:\n",
    "    The less experience the driver has, the more risk he/she will be\n",
    "    \"\"\"\n",
    "    if years <= 2: return 3\n",
    "    elif years <= 8: return 2\n",
    "    return 1\n",
    "\n",
    "def categorize_risk_index(risk_index: float):\n",
    "    \"\"\"\n",
    "    Input: risk index in the form of float\n",
    "    Returns: a string that represents the risk index category\n",
    "    \"\"\"\n",
    "    if risk_index <= 4: return 1\n",
    "    elif risk_index <= 6: return 2\n",
    "    return 3\n",
    "\n",
    "def categorize_attributes(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Input: a dataframe that contains the raw data but proccessed\n",
    "    Returns: a dataframe that contains the categorial columns mapped and the numerical columns binned\n",
    "    \"\"\"\n",
    "    categorical_columns = df.select_dtypes(exclude=['float64', 'int64'])\n",
    "    categorial_mapping = get_categorial_mapping(df, categorical_columns)\n",
    "    for col, mapping in categorial_mapping.items(): # assign the mapping to the categorial columns\n",
    "        df[col] = df[col].map(mapping)\n",
    "\n",
    "    df['CREDIT_SCORE'] = kbin_normal_distribution(df['CREDIT_SCORE'])\n",
    "    df['MILEAGE_EXPERIANCE_RATIO'] = df['ANNUAL_MILEAGE'] / (1 + df['DRIVING_EXPERIENCE'])\n",
    "    df['MILEAGE_EXPERIANCE_RATIO'] = kbin_exp_distribution(df['MILEAGE_EXPERIANCE_RATIO'])\n",
    "    df['ANNUAL_MILEAGE'] = kbin_normal_distribution(df['ANNUAL_MILEAGE'])\n",
    "    df['AGE'] = df['AGE'].apply(categorize_age_attribute)\n",
    "    df['EXPERIENCE_QUALITY'] = df['DRIVING_EXPERIENCE'] / (1 + df['PAST_ACCIDENTS'])\n",
    "    df['EXPERIENCE_QUALITY'] = kbin_exp_distribution(df['EXPERIENCE_QUALITY'])\n",
    "    df['DRIVING_EXPERIENCE'] = df['DRIVING_EXPERIENCE'].apply(categorize_driving_experience)\n",
    "    df['DRIVER_RISK_INDEX'] = 0.4 * df['SPEEDING_VIOLATIONS'] + 0.4 * df['PAST_ACCIDENTS'] + 0.2 * df['DRIVING_EXPERIENCE'] * df['AGE']\n",
    "    df['DRIVER_RISK_INDEX'] = df['DRIVER_RISK_INDEX'].apply(categorize_risk_index)\n",
    "    df['SPEEDING_VIOLATIONS'] = kbin_exp_distribution(df['SPEEDING_VIOLATIONS'])\n",
    "    df['PAST_ACCIDENTS'] = kbin_exp_distribution(df['PAST_ACCIDENTS'])\n",
    "    return df\n",
    "\n",
    "def pre_process(raw: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Input: a dataframe that contains the raw data\n",
    "    Returns: a dataframe that has been pre-processed using the logic below\n",
    "    \"\"\"\n",
    "    df = fill_missing_values(raw)\n",
    "    df = fix_irrational_driving_age(df)\n",
    "    df = categorize_attributes(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Test-Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(df: pd.DataFrame, ratio: float):\n",
    "    \"\"\"\n",
    "    Input: a dataframe that has been pre-processed and a ratio for the train and test set\n",
    "    Returns: train and test sets\n",
    "    \"\"\"\n",
    "    train = df.sample(frac = ratio)\n",
    "    test = df.drop(train.index)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_data(data: pd.DataFrame):\n",
    "    minmax_scaler = MinMaxScaler()\n",
    "    x = data.drop(columns=['OUTCOME'])\n",
    "    y = data['OUTCOME']\n",
    "    x_scaled = minmax_scaler.fit_transform(x)\n",
    "    return x_scaled, y\n",
    "\n",
    "def plot_confusion_matrix(y_test: pd.Series, y_pred: np.ndarray, labels=None):\n",
    "    \"\"\"\n",
    "    Plots the confusion matrix.\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    unique_labels = labels if labels else np.unique(y_test)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.colorbar()\n",
    "    plt.xticks(np.arange(cm.shape[1]), labels=unique_labels, rotation=45)\n",
    "    plt.yticks(np.arange(cm.shape[0]), labels=unique_labels)\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.tight_layout()\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, format(cm[i, j], 'd'), ha=\"center\", va=\"center\", color=\"black\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(df: pd.DataFrame, depth: int = None, criterion: str = 'gini', splitter: str = 'best'):\n",
    "    \"\"\"\n",
    "    Input: a dataframe that has been pre-processed and contains the train set\n",
    "    Returns: a decision tree that has been trained on the given set\n",
    "    \"\"\"\n",
    "    return DecisionTreeClassifier(max_depth=depth, criterion=criterion, splitter=splitter).fit(df.drop(columns = ['OUTCOME']), df['OUTCOME'])\n",
    "\n",
    "def visualize_tree(tree, feature_names, pdf_path=\"decision_tree.pdf\"):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      - tree: The trained decision tree model\n",
    "      - feature_names: List of feature names used in the training data\n",
    "    Outputs:\n",
    "      - A PDF file with a simplified and more readable visualization of the decision tree.\n",
    "    \"\"\"\n",
    "    with PdfPages(pdf_path) as pdf:\n",
    "        plt.figure(figsize=(30, 20))  # Increase figure size for larger bricks\n",
    "        plot_tree(\n",
    "            tree,\n",
    "            feature_names=feature_names,  # Use feature names for splits\n",
    "            class_names=['0', '1'],       # Use '0' and '1' for classes\n",
    "            filled=True,                  # Add colors\n",
    "            rounded=True,                 # Rounded nodes\n",
    "            fontsize=7                   # Set font size for better readability\n",
    "        )\n",
    "        plt.title(\"Decision Tree Visualization\", fontsize=20)  # Larger title\n",
    "        pdf.savefig()  # Save the current figure to the PDF\n",
    "        plt.close()\n",
    "    print(f\"Decision tree saved to {pdf_path}\")\n",
    "\n",
    "def get_maximum_accuracy_ratio(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Input: a dataframe that has been pre-processed\n",
    "    Returns: the maximum accuracy ratio of the decision tree\n",
    "    \"\"\"\n",
    "    accuracy_map = []\n",
    "    for i in range(10):\n",
    "        for ratio in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:\n",
    "            train, test = split_train_test(df, ratio=ratio)\n",
    "            tree = build_tree(train)\n",
    "            accuracy = tree.score(test.drop(columns=['OUTCOME']), test['OUTCOME'])\n",
    "            accuracy_map.append({'Iteration': i, 'Ratio': ratio, 'Accuracy': accuracy, 'Tree': tree})\n",
    "    accuracy_df = pd.DataFrame(accuracy_map)\n",
    "    accuracy_summary = accuracy_df.groupby('Ratio').agg({'Accuracy': 'mean'}).reset_index()\n",
    "    best_ratio_row = accuracy_summary[accuracy_summary['Accuracy'] == accuracy_summary['Accuracy'].max()]\n",
    "    return best_ratio_row['Ratio'].values[0]\n",
    "\n",
    "def grid_search_tree(df: pd.DataFrame, max_depth_range: range, criteria: list, splitters: list, ratio: float):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        - df: Pre-processed DataFrame\n",
    "        - max_depth_range: Range of max depths to test\n",
    "        - criteria: List of criteria to test (e.g., ['gini', 'entropy', 'log_loss'])\n",
    "        - splitters: List of splitters to test (e.g., ['best', 'random'])\n",
    "        - ratio: Train-test split ratio\n",
    "    Returns:\n",
    "        - A DataFrame with grid search results\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    train, test = split_train_test(df, ratio=ratio)\n",
    "\n",
    "    for criterion in criteria:\n",
    "        for splitter in splitters:\n",
    "            for depth in max_depth_range:\n",
    "                tree = build_tree(train, depth=depth, criterion=criterion, splitter=splitter)\n",
    "                accuracy = tree.score(test.drop(columns=['OUTCOME']), test['OUTCOME'])\n",
    "                results.append({\n",
    "                    'Criterion': criterion,\n",
    "                    'Splitter': splitter,\n",
    "                    'Max Depth': depth,\n",
    "                    'Accuracy': accuracy\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def plot_heatmaps(results: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Input: Results DataFrame from grid search\n",
    "    Displays: Heatmaps for Accuracy with Splitter as separate heatmaps\n",
    "    \"\"\"\n",
    "    splitters = results['Splitter'].unique()  # Get unique splitters\n",
    "    for splitter in splitters:\n",
    "        splitter_data = results[results['Splitter'] == splitter]\n",
    "        heatmap_data = splitter_data.pivot(index='Criterion', columns='Max Depth', values='Accuracy')\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.heatmap(heatmap_data, annot=True, fmt=\".3f\", cmap='YlGnBu', cbar=True)\n",
    "        plt.title(f\"Heatmap of Grid Search Results for Splitter = {splitter}\")\n",
    "        plt.xlabel('Max Depth')\n",
    "        plt.ylabel('Criterion')\n",
    "        plt.show()\n",
    "\n",
    "def find_best_combination(results: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Input: Results DataFrame from grid search\n",
    "    Returns: The best combination of max_depth, criterion, and splitter with the highest accuracy\n",
    "    \"\"\"\n",
    "    best_row = results.loc[results['Accuracy'].idxmax()]\n",
    "    return best_row\n",
    "\n",
    "def plot_3d_results(results: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Input: Results DataFrame from grid search\n",
    "    Displays: An interactive 3D scatter plot of Accuracy with Criterion, Splitter, and Max Depth\n",
    "    \"\"\"\n",
    "    fig = px.scatter_3d(\n",
    "        results,\n",
    "        x='Max Depth',      # X-axis\n",
    "        y='Criterion',      # Y-axis\n",
    "        z='Accuracy',       # Z-axis\n",
    "        color='Splitter',   # Color by splitter\n",
    "        symbol='Splitter',  # Different symbols for splitters\n",
    "        size='Accuracy',    # Size based on accuracy\n",
    "        title=\"3D Visualization of Grid Search Results\",\n",
    "        labels={\n",
    "            'Max Depth': 'Max Depth',\n",
    "            'Criterion': 'Criterion',\n",
    "            'Accuracy': 'Accuracy',\n",
    "            'Splitter': 'Splitter'\n",
    "        }\n",
    "    )\n",
    "    fig.update_traces(marker=dict(size=8, opacity=0.8))\n",
    "    fig.update_layout(scene=dict(\n",
    "        xaxis_title='Max Depth',\n",
    "        yaxis_title='Criterion',\n",
    "        zaxis_title='Accuracy'\n",
    "    ))\n",
    "    fig.show()\n",
    "\n",
    "def get_decision_tree(df: pd.DataFrame, params: dict = False):\n",
    "    \"\"\"\n",
    "    Input: a dataframe that has been pre-processed\n",
    "    Returns: the decision tree with the highest accuracy\n",
    "\n",
    "    Logic:\n",
    "    1. Split the data into train and test sets\n",
    "    2. Build a decision tree using the train set\n",
    "    3. Evaluate the accuracy of the decision tree on the test set\n",
    "    4. Repeat the process for 10 iterations\n",
    "    5. Find the best ratio of the train and test set in terms of tree accuracy\n",
    "    6. Find the best combination of the decision tree hyperparameters\n",
    "    7. Return the best decision tree\n",
    "    \"\"\"\n",
    "    # ratio = get_maximum_accuracy_ratio(df)\n",
    "    # max_depth_range = range(1, 20)\n",
    "    # criteria = ['gini', 'entropy', 'log_loss']\n",
    "    # splitters = ['best', 'random']\n",
    "    # results = grid_search_tree(df, max_depth_range, criteria, splitters, ratio)\n",
    "    # best_combination = find_best_combination(results)\n",
    "    # print(f\"The best combination is:\\n{best_combination}\")\n",
    "    # plot_heatmaps(results)\n",
    "    # plot_3d_results(results)\n",
    "    if params:\n",
    "        return build_tree(df, **params)\n",
    "    return build_tree(df)\n",
    "\n",
    "def get_results_per_tree(decision_tree, train, test):\n",
    "    X_train = train.drop(columns=['OUTCOME'])\n",
    "    y_train = train['OUTCOME']\n",
    "    X_test = test.drop(columns=['OUTCOME'])\n",
    "    y_test = test['OUTCOME']\n",
    "\n",
    "    train_predictions = decision_tree.predict(X_train)\n",
    "    test_predictions = decision_tree.predict(X_test)\n",
    "    train_f1 = f1_score(y_train, train_predictions)\n",
    "    test_f1 = f1_score(y_test, test_predictions) \n",
    "\n",
    "    print(f\"The F1 score of the decision tree on the train set is: {train_f1}\")\n",
    "    print(f\"The F1 score of the decision tree on the test set is: {test_f1}\")\n",
    "    feature_importance = decision_tree.feature_importances_\n",
    "    feature_names = train.drop(columns=['OUTCOME']).columns\n",
    "    feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance})\n",
    "    feature_importance_df = feature_importance_df.sort_values('Importance', ascending=False)\n",
    "    print(feature_importance_df)\n",
    "    # visualize_tree(decision_tree, train.drop(columns=['OUTCOME']).columns)\n",
    "\n",
    "def decision_tree_section(train: pd.DataFrame, test: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Gathers the decision tree section of the code\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        'depth': 8,\n",
    "        'criterion': 'entropy',\n",
    "        'splitter': 'best'\n",
    "    }\n",
    "    base_decision_tree = get_decision_tree(train)\n",
    "    modified_decision_tree = get_decision_tree(train, params)\n",
    "    # print(\"Base Decision Tree\")\n",
    "    # get_results_per_tree(base_decision_tree, train, test)\n",
    "    # print(\"\\nModified Decision Tree\")\n",
    "    # get_results_per_tree(modified_decision_tree, train, test)\n",
    "\n",
    "    return modified_decision_tree #, base_decision_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model_with_modified_params(x_train_scaled: pd.DataFrame, y_train: pd.Series, params: dict):\n",
    "    \"\"\"\n",
    "    Trains the NN model with modified params and returns the best model and its parameters.\n",
    "    \"\"\"\n",
    "    model = MLPClassifier()\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=params, cv=3, n_jobs=-1, scoring='accuracy')\n",
    "    grid_search.fit(x_train_scaled, y_train)\n",
    "    return grid_search.best_estimator_, grid_search.best_params_\n",
    "\n",
    "def check_nn_model_accuracy(nn_model: MLPClassifier, x: pd.DataFrame, y: pd.Series):\n",
    "    \"\"\"\n",
    "    Prints the accuracy of the NN model on the train and test sets.\n",
    "    \"\"\"\n",
    "    nn_model.fit(x, y)\n",
    "    y_pred = nn_model.predict(x)\n",
    "    f1_accuracy = f1_score(y, y_pred, average=\"weighted\")\n",
    "    return f1_accuracy\n",
    "\n",
    "def build_nn_model(x_train_scaled: pd.DataFrame, y_train: pd.Series = None, params: dict = None):\n",
    "    \"\"\"\n",
    "    Input: train set to train NN model, params that can be used to modify the model\n",
    "    Returns: NN model with the given params\n",
    "    \"\"\"\n",
    "    if not params:\n",
    "        return MLPClassifier()\n",
    "    return nn_model_with_modified_params(x_train_scaled, y_train, params)\n",
    "\n",
    "def plot_nn_heatmap(param_grid: dict, x_train_scaled: pd.DataFrame, y_train: pd.Series, x_test_scaled: pd.DataFrame, y_test: pd.Series):\n",
    "    \"\"\"\n",
    "    Generates heatmaps to visualize NN model accuracy for different parameter combinations.\n",
    "    \"\"\"\n",
    "    param_combinations = list(product(\n",
    "        param_grid['hidden_layer_sizes'], \n",
    "        param_grid['activation'], \n",
    "        param_grid['alpha'], \n",
    "        param_grid['max_iter']\n",
    "    ))\n",
    "\n",
    "    results = []\n",
    "    for params in param_combinations:\n",
    "        hidden_layer_sizes, activation, alpha, max_iter = params\n",
    "        model = MLPClassifier(\n",
    "            hidden_layer_sizes=hidden_layer_sizes,\n",
    "            activation=activation,\n",
    "            alpha=alpha,\n",
    "            max_iter=max_iter,\n",
    "            random_state=42\n",
    "        )\n",
    "        model.fit(x_train_scaled, y_train)\n",
    "        accuracy = model.score(x_test_scaled, y_test)\n",
    "        results.append({\n",
    "            'hidden_layer_sizes': hidden_layer_sizes,\n",
    "            'activation': activation,\n",
    "            'alpha': alpha,\n",
    "            'max_iter': max_iter,\n",
    "            'accuracy': accuracy\n",
    "        })\n",
    "\n",
    "    # Convert results to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    heatmap_plots = [\n",
    "        {\n",
    "            \"pivot_index\": \"activation\",\n",
    "            \"pivot_columns\": \"hidden_layer_sizes\",\n",
    "            \"title\": \"Activation vs Hidden Layer Sizes (Fixed Alpha)\",\n",
    "            \"constant_param\": \"alpha\"\n",
    "        },\n",
    "        {\n",
    "            \"pivot_index\": \"alpha\",\n",
    "            \"pivot_columns\": \"hidden_layer_sizes\",\n",
    "            \"title\": \"Alpha vs Hidden Layer Sizes (Fixed Activation)\",\n",
    "            \"constant_param\": \"activation\"\n",
    "        },\n",
    "        {\n",
    "            \"pivot_index\": \"alpha\",\n",
    "            \"pivot_columns\": \"activation\",\n",
    "            \"title\": \"Alpha vs Activation (Fixed Hidden Layer Sizes)\",\n",
    "            \"constant_param\": \"hidden_layer_sizes\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    for plot_config in heatmap_plots:\n",
    "        constant_param = plot_config[\"constant_param\"]\n",
    "        unique_constants = results_df[constant_param].unique()\n",
    "\n",
    "        for constant_value in unique_constants:\n",
    "            filtered_df = results_df[results_df[constant_param] == constant_value]\n",
    "            heatmap_data = filtered_df.pivot_table(\n",
    "                index=plot_config[\"pivot_index\"],\n",
    "                columns=plot_config[\"pivot_columns\"],\n",
    "                values=\"accuracy\",\n",
    "                aggfunc=\"mean\"\n",
    "            )\n",
    "\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            sns.heatmap(heatmap_data, annot=True, cmap='viridis', fmt=\".2f\", cbar=True)\n",
    "            plt.title(f\"{plot_config['title']} ({constant_param}={constant_value})\")\n",
    "            plt.xlabel(plot_config[\"pivot_columns\"])\n",
    "            plt.ylabel(plot_config[\"pivot_index\"])\n",
    "            plt.show()\n",
    "\n",
    "def print_model_details(model: MLPClassifier, x, y, params: dict = None):\n",
    "    if params:\n",
    "        print(f\"Model Details with the following parameters:\\n{json.dumps(params, indent=4)}\")\n",
    "        train_f1 = check_nn_model_accuracy(model, x, y)\n",
    "        test_f1 = check_nn_model_accuracy(model, x, y)\n",
    "        print(f\"Modifed Model F1 Score for train data: {train_f1 * 100:.2f}%\")\n",
    "        print(f\"Modifed Model F1 Score for test data: {test_f1 * 100:.2f}%\")\n",
    "    else:\n",
    "        base_train_f1 = check_nn_model_accuracy(model, x, y)\n",
    "        base_test_f1 = check_nn_model_accuracy(model, x, y)\n",
    "        print(f\"Base Model F1 Score for train data: {base_train_f1 * 100:.2f}%\\n\")\n",
    "        print(f\"Base Model F1 Score for test data: {base_test_f1 * 100:.2f}%\\n\")\n",
    "\n",
    "def neural_network_section(train: pd.DataFrame, test: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Gathers the neural network section of the code\n",
    "    \"\"\"\n",
    "    x_train_scaled, y_train = standardize_data(train) # = minmax_scaler.fit_transform(x_train)\n",
    "    x_test_scaled, y_test = standardize_data(test) # = minmax_scaler.transform(x_test)\n",
    "\n",
    "    params = {\n",
    "        'hidden_layer_sizes': [(50, 50), (50, 50, 50), (100, 100), (100, 100, 100)],\n",
    "        'activation': ['relu', 'identity', 'logistic', 'tanh'],\n",
    "        'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "        'learning_rate': ['constant', 'adaptive', 'invscaling'],\n",
    "        'max_iter': [200, 400]\n",
    "    }\n",
    "\n",
    "    # Base Model\n",
    "    default_model = build_nn_model(x_train_scaled, y_train)\n",
    "    # print_model_details(default_model, x_train_scaled, y_train)\n",
    "    # print_model_details(default_model, x_test_scaled, y_test)\n",
    "\n",
    "    # Modified Model\n",
    "    best_hyper_model, best_params = build_nn_model(x_train_scaled, y_train, params)\n",
    "    # print_model_details(best_hyper_model, x_train_scaled, y_train, best_params)\n",
    "    # print_model_details(best_hyper_model, x_test_scaled, y_test, best_params)\n",
    "\n",
    "    # plot_nn_heatmap(params, x_train_scaled, y_train, x_test_scaled, y_test)\n",
    "    return default_model #, best_hyper_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relabel_clusters(kmeans_clusters: np.ndarray, y_train: pd.Series):\n",
    "    \"\"\"\n",
    "    Relabels clusters to align with the actual labels using majority voting.\n",
    "    \"\"\"\n",
    "    mapping = {}\n",
    "    for cluster in np.unique(kmeans_clusters):\n",
    "        # Find the majority class in each cluster\n",
    "        cluster_indices = np.where(kmeans_clusters == cluster)[0]\n",
    "        majority_class = y_train.iloc[cluster_indices].mode()[0]\n",
    "        mapping[cluster] = majority_class\n",
    "    \n",
    "    # Map the clusters to the majority class labels\n",
    "    relabeled_clusters = np.array([mapping[cluster] for cluster in kmeans_clusters])\n",
    "    return relabeled_clusters\n",
    "\n",
    "def calculate_accuracy(y_train: pd.Series, relabeled_clusters: np.ndarray):\n",
    "    \"\"\"\n",
    "    Calculates the percentage of correctly clustered records.\n",
    "    \"\"\"\n",
    "    accuracy = f1_score(y_train, relabeled_clusters)\n",
    "    print(f\"Clustering Accuracy: {accuracy * 100:.2f}%\")\n",
    "    return accuracy\n",
    "\n",
    "def plot_accuracy_pie(accuracy: float):\n",
    "    \"\"\"\n",
    "    Plots the clustering accuracy as a pie chart.\n",
    "    \"\"\"\n",
    "    # Calculate correctly and incorrectly clustered percentages\n",
    "    correct_percentage = accuracy * 100\n",
    "    incorrect_percentage = 100 - correct_percentage\n",
    "    \n",
    "    # Data for the pie chart\n",
    "    labels = [\"Correctly Clustered\", \"Incorrectly Clustered\"]\n",
    "    sizes = [correct_percentage, incorrect_percentage]\n",
    "    colors = ['skyblue', 'lightcoral']\n",
    "    \n",
    "    # Plot the pie chart\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.pie(\n",
    "        sizes, \n",
    "        labels=labels, \n",
    "        autopct=lambda p: f'{p:.1f}%' if p > 5 else '',  # Show percentage if > 5%\n",
    "        startangle=140, \n",
    "        colors=colors, \n",
    "        explode=(0.1, 0)  # Slightly separate the correct slice\n",
    "    )\n",
    "    plt.title(\"KMeans Clustering Accuracy\")\n",
    "    plt.show()\n",
    "\n",
    "def create_kmeans_clusters(x_train_scaled: pd.DataFrame, clusters: int):\n",
    "    \"\"\"\n",
    "    Creates KMeans clusters and returns the cluster labels\n",
    "    \"\"\"\n",
    "    kmeans = KMeans(n_clusters=clusters, random_state=42)\n",
    "    train_clusters = kmeans.fit_predict(x_train_scaled)\n",
    "    return train_clusters\n",
    "\n",
    "def print_pca_variance(pca: PCA):\n",
    "    print(f\"Explained Variance Ratio: {pca.explained_variance_ratio_}\")\n",
    "    print(f\"Total Explained Variance: {sum(pca.explained_variance_ratio_)}\")\n",
    "    \n",
    "def plot_kmeans_clusters(x_train_pca: pd.DataFrame, clusters: pd.Series):\n",
    "    \"\"\"\n",
    "    Plots the clusters\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    scatter = plt.scatter(x_train_pca[:, 0], x_train_pca[:, 1], c=clusters, cmap='viridis', s=10)\n",
    "    plt.title(\"K-Means Clustering with PCA\")\n",
    "    plt.xlabel(\"PCA Component 1\")\n",
    "    plt.ylabel(\"PCA Component 2\")\n",
    "    cbar = plt.colorbar(scatter)\n",
    "    cbar.set_label(\"Cluster Label\")\n",
    "    plt.show()  \n",
    "\n",
    "def plot_original_cluster(x_train_pca: pd.DataFrame, y_train_scaled: pd.DataFrame):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.scatter(x_train_pca[:, 0], x_train_pca[:, 1], c=y_train_scaled, cmap='coolwarm', alpha=0.5)\n",
    "    plt.title(\"Actual Labels with PCA\")\n",
    "    plt.xlabel(\"PCA Component 1\",fontsize=14)\n",
    "    plt.ylabel(\"PCA Component 2\",fontsize=14)\n",
    "    plt.colorbar(label='Actual Label')\n",
    "    plt.show()\n",
    "\n",
    "def plot_cluster_class_distribution(clusters, y_train):\n",
    "    \"\"\"\n",
    "    Plots the distribution of KMeans clusters and the original classes on the same graph.\n",
    "    \"\"\"\n",
    "    # Calculate cluster and class distributions\n",
    "    cluster_distribution = pd.Series(clusters).value_counts().sort_index()\n",
    "    class_distribution = y_train.value_counts().sort_index()\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(cluster_distribution.index, cluster_distribution.values, marker='o', label=\"KMeans Clusters\", linestyle='--')\n",
    "    plt.plot(class_distribution.index, class_distribution.values, marker='o', label=\"Original Classes\", linestyle='-')\n",
    "    plt.title(\"Cluster vs Class Distribution\", fontsize=14)\n",
    "    plt.xlabel(\"Cluster/Class Labels\", fontsize=12)\n",
    "    plt.ylabel(\"Count\", fontsize=12)\n",
    "    plt.xticks(cluster_distribution.index)\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def cluster_set(x, y):\n",
    "    \"\"\"\n",
    "    This function clusters the data using KMeans clustering.\n",
    "    \"\"\"\n",
    "    kmeans_clusters = create_kmeans_clusters(x, clusters=2)  # 2 clusters because a person could either get an insurance or not\n",
    "\n",
    "    # Perform PCA for dimensionality reduction for visualization\n",
    "    pca = PCA(n_components=2)\n",
    "    x_pca = pca.fit_transform(x)\n",
    "    print_pca_variance(pca)\n",
    "    plot_kmeans_clusters(x_pca, kmeans_clusters)\n",
    "    plot_original_cluster(x_pca, y)\n",
    "    plot_cluster_class_distribution(kmeans_clusters, y)\n",
    "    \n",
    "    # Relabel clusters and calculate accuracy\n",
    "    relabeled_clusters = relabel_clusters(kmeans_clusters, y)\n",
    "    accuracy = calculate_accuracy(y, relabeled_clusters)\n",
    "\n",
    "    # Visualize accuracy\n",
    "    plot_accuracy_pie(accuracy) \n",
    "\n",
    "def clustering_section(train: pd.DataFrame, test: pd.DataFrame):\n",
    "    x_train_scaled, y_train = standardize_data(train)\n",
    "    x_test_scaled, y_test = standardize_data(test)\n",
    "\n",
    "    cluster_set(x_train_scaled, y_train)\n",
    "    cluster_set(x_test_scaled, y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm_model(x: np.ndarray, y: pd.Series, params: dict = None):\n",
    "    \"\"\"\n",
    "    Trains an SVM model. If params are provided, performs GridSearchCV for hyperparameter tuning otherwise trains a default model.\n",
    "    \"\"\"\n",
    "    if not params:\n",
    "        svm = SVC(random_state=42)\n",
    "        svm.fit(x, y)\n",
    "        return svm, None\n",
    "    \n",
    "    grid_search = GridSearchCV(SVC(random_state=42), params, scoring='f1', cv=5, verbose=1, n_jobs=-1)\n",
    "    grid_search.fit(x, y)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    return best_model, grid_search.best_params_\n",
    "\n",
    "def evaluate_svm_model(svm, x: np.ndarray, y: pd.Series):\n",
    "    \"\"\"\n",
    "    Evaluates the SVM model on unseen test data and returns the F1 score and classification report.\n",
    "    \"\"\"\n",
    "    y_pred = svm.predict(x)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    return y_pred, f1\n",
    "\n",
    "def describe_model_results(model, f1: float, y: pd.Series, y_pred: np.ndarray):\n",
    "    \"\"\"\n",
    "    Describes the model results with the F1 score, classification report, and confusion matrix.\n",
    "    \"\"\"\n",
    "    print(f\"F1 Score: {f1 * 100:.2f}%\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y, y_pred))\n",
    "    plot_confusion_matrix(y, y_pred)\n",
    "\n",
    "def svm_section(train: pd.DataFrame, test: pd.DataFrame):\n",
    "    x_train_scaled, y_train = standardize_data(train)\n",
    "    x_test_scaled, y_test = standardize_data(test)\n",
    "\n",
    "    params = {\n",
    "        'kernel': ['linear', 'rbf', 'poly'],\n",
    "        'C': [0.1, 1, 10],\n",
    "        'gamma': [0.01, 0.1]\n",
    "    }\n",
    "    models_and_scores = {}\n",
    "\n",
    "    train_base_svm, _ = train_svm_model(x_train_scaled, y_train)\n",
    "    train_y_pred_base, train_f1_base = evaluate_svm_model(train_base_svm, x_train_scaled, y_train)\n",
    "    # print(\"Base SVM Model Train Results:\")\n",
    "    # describe_model_results(train_base_svm, train_f1_base, y_train, train_y_pred_base)\n",
    "    models_and_scores['train_base_svm'] = (train_base_svm, train_f1_base)\n",
    "\n",
    "    test_base_svm, _ = train_svm_model(x_test_scaled, y_test)\n",
    "    test_y_pred_base, test_f1_base = evaluate_svm_model(test_base_svm, x_test_scaled, y_test)\n",
    "    # print(\"Base SVM Model Test Results:\")\n",
    "    # describe_model_results(test_base_svm, test_f1_base, y_test, test_y_pred_base)\n",
    "    models_and_scores['test_base_svm'] = (test_base_svm, test_f1_base)\n",
    "\n",
    "    train_tuned_svm, train_best_params = train_svm_model(x_train_scaled, y_train, params)\n",
    "    train_y_pred_tuned, train_f1_tuned = evaluate_svm_model(train_tuned_svm, x_train_scaled, y_train)\n",
    "    # print(\"Tuned SVM Model Train Results:\")\n",
    "    # print(f\"Model's Parameters: {json.dumps(train_best_params, indent=4)}\")\n",
    "    # describe_model_results(train_tuned_svm, train_f1_tuned, y_train, train_y_pred_tuned)\n",
    "    models_and_scores['train_tuned_svm'] = (train_tuned_svm, train_f1_tuned)\n",
    "\n",
    "    test_tuned_svm, test_best_params = train_svm_model(x_test_scaled, y_test, params)\n",
    "    test_y_pred_tuned, test_f1_tuned = evaluate_svm_model(test_tuned_svm, x_test_scaled, y_test)\n",
    "    # print(\"Tuned SVM Model Test Results:\")\n",
    "    # print(f\"Model's Parameters: {json.dumps(test_best_params, indent=4)}\")\n",
    "    # describe_model_results(test_tuned_svm, test_f1_tuned, y_test, test_y_pred_tuned)\n",
    "    models_and_scores['test_tuned_svm'] = (test_tuned_svm, test_f1_tuned)\n",
    "\n",
    "    best_model = max(models_and_scores.values(), key=lambda x: x[1])[0]\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_file = pd.read_csv(file_path).drop(columns = ['ID'])\n",
    "data = pre_process(raw_file)\n",
    "train, test = split_train_test(data, ratio = 0.8)\n",
    "\n",
    "## Models\n",
    "# dt = decision_tree_section(train, test)\n",
    "nn = neural_network_section(train, test)\n",
    "# clustering_section(train, test)\n",
    "# svm = svm_section(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix Using The Selected Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score is 87.53%\n"
     ]
    }
   ],
   "source": [
    "scaled_x, y = standardize_data(test)\n",
    "nn.fit(scaled_x, y)\n",
    "predicted_y = nn.predict(scaled_x)\n",
    "plot_confusion_matrix(y, predicted_y)\n",
    "print(f\"F1 Score is {f1_score(y, predicted_y, average='weighted') * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_predict = pd.read_csv('X_test.csv').drop(columns = ['ID'])\n",
    "to_predict = pre_process(to_predict)\n",
    "to_predict['OUTCOME'] = '' # just so we could use the normalize function we made\n",
    "x, _ = standardize_data(to_predict)\n",
    "\n",
    "predicted_y = nn.predict(x)\n",
    "carinsurance_G9_ytest = pd.DataFrame({'target': predicted_y})\n",
    "carinsurance_G9_ytest.to_excel('carinsurance_G9_ytest.xlsx', index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".ml_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
